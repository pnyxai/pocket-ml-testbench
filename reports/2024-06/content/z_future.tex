\section{Future Work}\label{sec:z}

So we have created a scalable and organized \gls{LM} evaluation workflow. But does this have to end here? What other possibilities are open?

We believe that the methodology presented throughout the different reports is abstract enough to be able to implement many ideas on top of the \gls{MLTB}. Our main ambitions are the following:

\subsection*{More leaderboards}

The \gls{HFOLML} is not the only leaderboard out there, there are many other leaderboards that could be interesting to replicate, for example:
\begin{itemize}
    \item \textcolor{red}{Completa con las otras, poneles referencias}
\end{itemize}

\subsection*{More Tests}

For example, more specific evaluations could be added for \glspl{LM}, such as the so-called "function call evaluation" \cite{patil_gorilla_2023}. 
On the other hand, if the network wants to add support for multimodal models, specific benchmarks \cite{yue_mmmu_2024} should be adapted for these cases. 

Also we can develop custom test, or generative tests to counter the overspecialization (or contamination) of new models in the mainstream tests. 
The last can alert about data leakage, a common problem during the traing of \glspl{LM} \cite{zhang_careful_2024, golchin_data_2024, xu_benchmarking_2024, balloccu_leak_2024}, both closed and open source. 

\subsection*{Model Signatures}

Getting signatures from a model is not restricted to getting a tokenizer. The concept of a signature is to identify if a model is of a given kind and track its changes. We might not be able to tell (confidently) the name of the model being staked in the POKT network but we can find all models of the same kind and group them by means of random signatures.

Also there are techniques likes watermarking~\cite{kirchenbauer2023watermark} that could be useful to implement in POKT and the \gls{MLTB} can be used to calculate and track such signatures.

\subsection*{On-chain}

The ideal \gls{ML} test suite should be one developed by a big community and implemented by parties with no conflicts of interest~\footnote{Model providers cannot be trusted to provide service with models that are the same as what they publish in journals \cite{chen_how_2023}.}. 
We consider this work as an actionable first step towards the descentralization of \gls{ML} tests, and we want to explore ways of enabling a crypto-economic incentive for providing this service, something close to the phylosofy of the POKT Network watchers~\footnote{For reference, a description of a watcher actor can be found here: \url{https://github.com/pokt-network/pocket-network-protocol/blob/main/utility/README.md\#33-fisherman-protocol}}.
