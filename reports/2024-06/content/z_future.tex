\section{Future Work}\label{sec:z}

So we have a scalable and organized LM evaluation workflow. But does this have to end here? What other possibilities are open?

At POKTscan and PNYX we believe that the methodology presented throughout the different reports is abstract enough to be able to include other types of benchmarks. 
For example, more specific evaluations could be added for \gls{LM}, such as the so-called "function call evaluation" \textcolor{red}{quote}. 
On the other hand, if the network wants to add support for multimodal models, specific \textcolor{red}{citation} benchmarks should be adapted for these cases. 

\textcolor{red}{COMPLET}
